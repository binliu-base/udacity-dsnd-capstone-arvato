{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:08:04.721955Z",
     "start_time": "2020-03-10T15:08:03.346958Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import hp\n",
    "import lightgbm as lgb\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "sys.path += ['./ilikeds']\n",
    "import eda \n",
    "import helper_functions as h\n",
    "import train_classifier as t\n",
    "\n",
    "import warnings                             \n",
    "warnings.filterwarnings('ignore')\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:49.363567Z",
     "start_time": "2020-03-10T14:50:46.049567Z"
    }
   },
   "outputs": [],
   "source": [
    "# load in the data\n",
    "# azdias = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_AZDIAS_052018.csv', sep=';')\n",
    "# customers = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_CUSTOMERS_052018.csv', sep=';')\n",
    "\n",
    "azdias = pd.read_pickle ('../data/azdias.p')    \n",
    "customers = pd.read_pickle ('../data/customers.p')    \n",
    "\n",
    "sampling_rate = 0.01\n",
    "r=np.random.randint(0, azdias.shape[0], int(azdias.shape[0]*sampling_rate))\n",
    "azdias=azdias.loc[r,:].copy()\n",
    "r=np.random.randint(0, customers.shape[0], int(customers.shape[0]*sampling_rate))\n",
    "customers=customers.loc[r,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:00:17.385703Z",
     "start_time": "2020-03-10T15:00:17.363705Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in feature info file\n",
    "feat_info = pd.read_csv('./feats_info.csv', sep=';', names=['feat', 'type', 'unknow'])\n",
    "feat_info.set_index('feat', inplace =True)\n",
    "feat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:50.963564Z",
     "start_time": "2020-03-10T14:50:49.416567Z"
    }
   },
   "outputs": [],
   "source": [
    "# create  a EDA  instance for Azdias.\n",
    "eda_azdias= eda.EDA(azdias, feat_info, label = 'Azdias')\n",
    "\n",
    "# create  a EDA  instance for Azdias. for  customers\n",
    "eda_customers= eda.EDA(customers, feat_info, label = 'Customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:50.978567Z",
     "start_time": "2020-03-10T14:50:50.967569Z"
    }
   },
   "outputs": [],
   "source": [
    "type(feat_info.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:51.009566Z",
     "start_time": "2020-03-10T14:50:50.982568Z"
    }
   },
   "outputs": [],
   "source": [
    "mixed = eda_azdias.feat_info[ (eda_azdias.feat_info.type == 'mixed') & (eda_azdias.feat_info.is_drop == 0)]\n",
    "mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:51.025568Z",
     "start_time": "2020-03-10T14:50:51.013567Z"
    }
   },
   "outputs": [],
   "source": [
    "####  Define action dictionary \n",
    "# action_dic ={\n",
    "#     1:  'drop: high missing values',\n",
    "#     2:  'drop: duplicated',\n",
    "#     3:  're-encoding: mapping',    \n",
    "#     4:  're-encoding: logarithmic scaling',        \n",
    "#     5:  'split',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:51.041569Z",
     "start_time": "2020-03-10T14:50:51.030568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing the three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP') in Customers\n",
    "feats_customers_excl  = list(set(eda_customers.data.columns) - set(eda_azdias.data.columns))\n",
    "feats_customers_excl\n",
    "eda_customers.data.drop(columns = feats_customers_excl, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T14:54:12.817463Z",
     "start_time": "2020-02-28T14:54:12.808465Z"
    }
   },
   "source": [
    "####  Step 1:  Converting of missing and unknown data to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:54.538569Z",
     "start_time": "2020-03-10T14:50:51.046568Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.missing2nan()\n",
    "eda_customers.missing2nan()\n",
    "\n",
    "# Re-Collecting feature stats\n",
    "eda_azdias.update_stats()\n",
    "eda_customers.update_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step 2: Remove rows and columns with high miss values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Deleting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:54.870567Z",
     "start_time": "2020-03-10T14:50:54.541569Z"
    }
   },
   "outputs": [],
   "source": [
    "rows_n_nans = azdias.isnull().sum(axis=1)\n",
    "plt.hist(rows_n_nans / azdias.shape[1], bins=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:54.966567Z",
     "start_time": "2020-03-10T14:50:54.876566Z"
    }
   },
   "outputs": [],
   "source": [
    "_, rows_droped = h.split_dataset(azdias, threshold=0.25)\n",
    "n_deleted_rows = rows_droped.shape[0]\n",
    "print(f'Before delete the missing rows, {eda_azdias} has {eda_azdias.data.shape[0]} rows')\n",
    "azdias.drop(index = rows_droped.index, inplace =True)\n",
    "print(f'After delete the missing rows, {eda_azdias} has {eda_azdias.data.shape[0]} rows')\n",
    "print(f'Delete {n_deleted_rows} rows in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:55.014567Z",
     "start_time": "2020-03-10T14:50:54.972566Z"
    }
   },
   "outputs": [],
   "source": [
    "_, rows_droped = h.split_dataset(customers, threshold=0.25)\n",
    "n_deleted_rows = rows_droped.shape[0]\n",
    "print(f'Before delete the high missing rate rows, {eda_customers} has {eda_customers.data.shape[0]} rows')\n",
    "eda_customers.data.drop(index = rows_droped.index, inplace =True)\n",
    "print(f'After delete the hitg missing rate rows, {eda_customers} has {eda_customers.data.shape[0]} rows')\n",
    "print(f'Delete {n_deleted_rows} rows in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Deleteing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:55.264567Z",
     "start_time": "2020-03-10T14:50:55.019566Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.feat_info.percent_of_nans.sort_values().hist(bins = 40, alpha = 0.7)\n",
    "plt.xlabel('Missing Rate ')\n",
    "plt.ylabel('Num Of Features')\n",
    "plt.title('Distribution of missing value per column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:55.280567Z",
     "start_time": "2020-03-10T14:50:55.270566Z"
    }
   },
   "outputs": [],
   "source": [
    "thr_col_missing = 0.6\n",
    "feats_high_missing_azdias = eda_azdias.feat_info.loc[eda_azdias.feat_info.percent_of_nans > thr_col_missing].index\n",
    "feats_high_missing_azdias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:55.311567Z",
     "start_time": "2020-03-10T14:50:55.282569Z"
    }
   },
   "outputs": [],
   "source": [
    "feats_high_missing_customers = eda_customers.feat_info.loc[eda_customers.feat_info.percent_of_nans >thr_col_missing ].index\n",
    "feats_high_missing_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:55.326565Z",
     "start_time": "2020-03-10T14:50:55.315566Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Get features with high missing rates in both datasets\n",
    "feats_high_missing = set(feats_high_missing_azdias).intersection(set(feats_high_missing_customers))\n",
    "feats_high_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:55.357565Z",
     "start_time": "2020-03-10T14:50:55.331566Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.feat_info.loc[feats_high_missing,'action'] = h.action_dic[1]\n",
    "eda_azdias.feat_info.loc[feats_high_missing,'is_drop'] = 1\n",
    "\n",
    "eda_customers.feat_info.loc[feats_high_missing,'action'] = h.action_dic[1]\n",
    "eda_customers.feat_info.loc[feats_high_missing,'is_drop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:55.420565Z",
     "start_time": "2020-03-10T14:50:55.361567Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eda_azdias.feat_info.loc[feats_high_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:56.680565Z",
     "start_time": "2020-03-10T14:50:55.423567Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.data.drop(columns = list(feats_high_missing), inplace =True)\n",
    "eda_customers.data.drop(columns = list(feats_high_missing), inplace =True)\n",
    "\n",
    "# Re-Collecting feature stats\n",
    "eda_azdias.update_stats()\n",
    "eda_customers.update_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T11:31:27.440073Z",
     "start_time": "2020-03-06T11:31:27.428072Z"
    }
   },
   "source": [
    "#### Step 3.  Remove duplicated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:58.322566Z",
     "start_time": "2020-03-10T14:50:56.683566Z"
    }
   },
   "outputs": [],
   "source": [
    "feats_fein =[x for x in eda_azdias.data.columns if x.endswith( '_FEIN')]\n",
    "feats_grob = [x for x in eda_azdias.data.columns if x.endswith( '_GROB')]\n",
    "feats_duplicate = [x for x in zip(pd.Series(feats_grob).sort_values(), pd.Series(feats_fein).sort_values())]\n",
    "h.plot_2feats_comparison(eda_azdias.data, feats_duplicate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:58.342567Z",
     "start_time": "2020-03-10T14:50:58.329569Z"
    }
   },
   "outputs": [],
   "source": [
    "# CAMEO_DEU_2015 and CAMEO_DEUG_2015 are both describing the wealth and life stage topology but at different scales. I've decided to keep CAMEO_DEUG_2015 which describes the information at a rough scale and drop CAMEO_DEU_2015. Another reason for dropping this feature is that it contains over 40 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:58.358567Z",
     "start_time": "2020-03-10T14:50:58.346568Z"
    }
   },
   "outputs": [],
   "source": [
    "feats_duplicated = ['ALTERSKATEGORIE_FEIN', 'LP_FAMILIE_FEIN', 'LP_LEBENSPHASE_FEIN', 'LP_STATUS_GROB', 'CAMEO_DEU_2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:58.374566Z",
     "start_time": "2020-03-10T14:50:58.366566Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.feat_info.loc[feats_duplicated,'action'] = h.action_dic[2]\n",
    "eda_azdias.feat_info.loc[feats_duplicated,'is_drop'] = 1\n",
    "\n",
    "eda_customers.feat_info.loc[feats_duplicated,'action'] = h.action_dic[2]\n",
    "eda_customers.feat_info.loc[feats_duplicated,'is_drop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:59.490565Z",
     "start_time": "2020-03-10T14:50:58.381568Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.data.drop(columns = list(feats_duplicated), inplace =True)\n",
    "eda_customers.data.drop(columns = list(feats_duplicated), inplace =True)\n",
    "\n",
    "# Re-Collecting feature stats\n",
    "eda_azdias.update_stats()\n",
    "eda_customers.update_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:59.522566Z",
     "start_time": "2020-03-10T14:50:59.492570Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.feat_info.loc[feats_duplicated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Re-encodings features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.  Re-encodings binary/categorical/mixed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:59.552567Z",
     "start_time": "2020-03-10T14:50:59.526565Z"
    }
   },
   "outputs": [],
   "source": [
    "feats_encoding = [\n",
    "                  'OST_WEST_KZ',\n",
    "                  'CAMEO_DEUG_2015',\n",
    "#                   'CAMEO_DEU_2015',\n",
    "                  'CAMEO_INTL_2015',\n",
    "#                   'EINGEFUEGT_AM',\n",
    "#                   'D19_LETZTER_KAUF_BRANCHE',    \n",
    "]\n",
    "\n",
    "# h.check_features(eda_azdias, encoding)     \n",
    "for x in feats_encoding:\n",
    "     print(x, eda_azdias.data[x].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:59.584567Z",
     "start_time": "2020-03-10T14:50:59.555568Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in feats_encoding:\n",
    "    eda_azdias.re_encoding(x)\n",
    "    eda_customers.re_encoding(x)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T07:34:21.915303Z",
     "start_time": "2020-03-08T07:34:21.903302Z"
    }
   },
   "source": [
    "b.  Re-encodings numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:59.616565Z",
     "start_time": "2020-03-10T14:50:59.588565Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.feat_info.loc[(eda_azdias.feat_info.type == 'numeric') & (eda_azdias.feat_info.is_drop == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:59.648567Z",
     "start_time": "2020-03-10T14:50:59.619567Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_feats = eda_azdias.feat_info.loc[(eda_azdias.feat_info.type == 'numeric') & (eda_azdias.feat_info.is_drop == 0)].index\n",
    "numeric_feats = numeric_feats.drop(['EINGEZOGENAM_HH_JAHR', 'GEBURTSJAHR', 'MIN_GEBAEUDEJAHR'])\n",
    "data = eda_azdias.data[numeric_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:59.664566Z",
     "start_time": "2020-03-10T14:50:59.652567Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.plotting.scatter_matrix(data, alpha = 0.3, figsize = (20,12), diagonal = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ANZ_HAUSHALTE_AKTIV appears rather highly correlated with ANZ_STATISTISCHE_HAUSHALTE.  so I decide delete ANZ_STATISTISCHE_HAUSHALTE and keep ANZ_HAUSHALTE_AKTIV. \n",
    "- ANZ_HAUSHALTE_AKTIV and KBA13_ANZAHL_PKW appear to have a skewed distribution,  I will apply the natural logarithmic transformation to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:50:59.696566Z",
     "start_time": "2020-03-10T14:50:59.669566Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.feat_info.loc['ANZ_STATISTISCHE_HAUSHALTE' ,['is_drop', 'action']] = 1,  h.action_dic[2]\n",
    "eda_customers.feat_info.loc['ANZ_STATISTISCHE_HAUSHALTE' ,['is_drop', 'action']]  = 1,  h.action_dic[2]\n",
    "\n",
    "eda_azdias.data['ANZ_HAUSHALTE_AKTIV'] =  np.log(eda_azdias.data['ANZ_HAUSHALTE_AKTIV'] +2)\n",
    "eda_azdias.data['KBA13_ANZAHL_PKW'] =  np.log(eda_azdias.data['KBA13_ANZAHL_PKW'])\n",
    "\n",
    "eda_customers.data['ANZ_HAUSHALTE_AKTIV'] =  np.log(eda_customers.data['ANZ_HAUSHALTE_AKTIV'] +2)\n",
    "eda_customers.data['KBA13_ANZAHL_PKW'] =  np.log(eda_customers.data['KBA13_ANZAHL_PKW'])\n",
    "\n",
    "eda_azdias.feat_info.loc['ANZ_STATISTISCHE_HAUSHALTE','action'] =h.action_dic[4]\n",
    "eda_customers.feat_info.loc['ANZ_STATISTISCHE_HAUSHALTE','action']  = h.action_dic[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:00.678567Z",
     "start_time": "2020-03-10T14:50:59.700568Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(eda_azdias.data[['ANZ_HAUSHALTE_AKTIV', 'KBA13_ANZAHL_PKW']] , alpha = 0.3, figsize = (20,12), diagonal = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:01.804567Z",
     "start_time": "2020-03-10T14:51:00.682570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Re-Collecting feature stats\n",
    "eda_azdias.update_stats()\n",
    "eda_customers.update_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T07:38:48.175159Z",
     "start_time": "2020-02-29T07:38:48.168158Z"
    }
   },
   "source": [
    "####  Step 5. Split Mixed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:01.835567Z",
     "start_time": "2020-03-10T14:51:01.807566Z"
    }
   },
   "outputs": [],
   "source": [
    "# mixed = eda_azdias.feat_info[ (eda_azdias.feat_info['type'] == 'mixed') & (eda_azdias.feat_info.is_drop == '0')]\n",
    "mixed_feats = eda_azdias.feat_info[ (eda_azdias.feat_info.type == 'mixed') & (eda_azdias.feat_info.is_drop == 0)]\n",
    "mixed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:02.106566Z",
     "start_time": "2020-03-10T14:51:01.838567Z"
    }
   },
   "outputs": [],
   "source": [
    "# mixed_feats = ['CAMEO_INTL_2015', 'LP_LEBENSPHASE_GROB', 'PRAEGENDE_JUGENDJAHRE', 'EINGEFUEGT_AM']\n",
    "for x in mixed_feats.index:\n",
    "    eda_azdias.split_mixed_feat(x)\n",
    "    eda_customers.split_mixed_feat(x)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:02.138566Z",
     "start_time": "2020-03-10T14:51:02.111566Z"
    }
   },
   "outputs": [],
   "source": [
    "feats_splited = ['CAMEO_INTL_2015_SPLIT_WEALTH', 'CAMEO_INTL_2015_SPLIT_LIFE_STAGE','LP_LEBENSPHASE_GROB_SPLIT_FAMILY','LP_LEBENSPHASE_GROB_SPLIT_AGE','LP_LEBENSPHASE_GROB_SPLIT_INCOME','PRAEGENDE_JUGENDJAHRE_SPLIT_DECADE','PRAEGENDE_JUGENDJAHRE_SPLIT_MOVEMENT']\n",
    "eda_azdias.data[feats_splited]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:02.218565Z",
     "start_time": "2020-03-10T14:51:02.143568Z"
    }
   },
   "outputs": [],
   "source": [
    "feats_splited_info = pd.DataFrame({\n",
    "    'type': pd.Series('categorical', index = feats_splited),\n",
    "    'unknow': pd.Series('[]', index = feats_splited)},\n",
    "index = feats_splited)\n",
    "                \n",
    "feat_info_split = eda_azdias.build_feat_info(feats_splited_info)\n",
    "eda_azdias.feat_info= pd.concat([eda_azdias.feat_info, feat_info_split], sort = False)\n",
    "# eda_azdias.feat_info\n",
    "\n",
    "feat_info_split = eda_customers.build_feat_info(feats_splited_info)\n",
    "eda_customers.feat_info= pd.concat([eda_customers.feat_info, feat_info_split], sort = False)\n",
    "# eda_customers.feat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:03.400565Z",
     "start_time": "2020-03-10T14:51:02.220566Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.update_stats()\n",
    "eda_customers.update_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.  Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:03.477565Z",
     "start_time": "2020-03-10T14:51:03.403568Z"
    }
   },
   "outputs": [],
   "source": [
    "# ordinal_feats = eda_azdias.feat_info[ (eda_azdias.feat_info.type == 'ordinal') & (eda_azdias.feat_info.is_drop == 0)].index\n",
    "# len(ordinal_feats)\n",
    "# eda_azdias.feat_info.loc['D19_LETZTER_KAUF_BRANCHE']\n",
    "obj_feats = eda_azdias.data.select_dtypes(include=['object']).columns\n",
    "eda_azdias.feat_info.loc[obj_feats ,['is_drop', 'action']] = 1, h.action_dic[8]   \n",
    "eda_customers.feat_info.loc[obj_feats,['is_drop', 'action']] = 1, h.action_dic[8]   \n",
    "\n",
    "eda_azdias.data.drop(columns = obj_feats, inplace =True)\n",
    "eda_customers.data.drop(columns = obj_feats, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:03.508566Z",
     "start_time": "2020-03-10T14:51:03.482567Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.feat_info.loc['LNR' ,['is_drop', 'action']] = 1, h.action_dic[9]   \n",
    "eda_customers.feat_info.loc[obj_feats,['is_drop', 'action']] = 1, h.action_dic[9]   \n",
    "\n",
    "eda_azdias.data.drop(columns = 'LNR', inplace =True)\n",
    "eda_customers.data.drop(columns = 'LNR', inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:03.524566Z",
     "start_time": "2020-03-10T14:51:03.512567Z"
    }
   },
   "outputs": [],
   "source": [
    "# eda_azdias.feat_info[eda_azdias.feat_info.is_drop == 0].value_distinct.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:03.540567Z",
     "start_time": "2020-03-10T14:51:03.528567Z"
    }
   },
   "outputs": [],
   "source": [
    "# eda_azdias.feat_info.loc[['LNR','KBA13_ANZAHL_PKW','ANZ_HAUSHALTE_AKTIV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:08.937566Z",
     "start_time": "2020-03-10T14:51:03.544567Z"
    }
   },
   "outputs": [],
   "source": [
    "outlier_feats = eda_azdias.feat_info[ eda_azdias.feat_info.is_drop == 0].index\n",
    "eda_azdias.clean_outlier(outlier_feats)\n",
    "eda_customers.clean_outlier(outlier_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:08.953567Z",
     "start_time": "2020-03-10T14:51:08.942567Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# h.plot_boxplot_comparison_2eda(eda_azdias, eda_customers, ordinal_feats[:100], figsize= (20,  200), hspace=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:08.968566Z",
     "start_time": "2020-03-10T14:51:08.959567Z"
    }
   },
   "outputs": [],
   "source": [
    "# outlier_feats=[\n",
    "#     'D19_SOZIALES',\n",
    "#     'D19_KONSUMTYP',\n",
    "#     'D19_KONSUMTYP_MAX',\n",
    "#     'ZABEOTYP',\n",
    "#     'CJT_TYP_1',\n",
    "#     'CJT_TYP_2',\n",
    "#     'CJT_TYP_3',\n",
    "#     'CJT_TYP_4',\n",
    "#     'CJT_TYP_5',\n",
    "#     'CJT_TYP_6',\n",
    "#     'KOMBIALTER',\n",
    "#     'LP_LEBENSPHASE_GROB_SPLIT_AGE',\n",
    "#     'LP_LEBENSPHASE_GROB_SPLIT_INCOME',\n",
    "#     'PRAEGENDE_JUGENDJAHRE_SPLIT_MOVEMENT',\n",
    "#     'ANZ_HAUSHALTE_AKTIV' , 'ANZ_PERSONEN','KBA13_ANZAHL_PKW',\n",
    "# ]\n",
    "\n",
    "# df_b = eda_customers.data[outlier_feats].copy()\n",
    "# df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:08.983567Z",
     "start_time": "2020-03-10T14:51:08.973567Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cat_feats = eda_azdias.feat_info.loc[(eda_azdias.feat_info.type == 'categorical') & (eda_azdias.feat_info.is_drop == 0)].index\n",
    "# h.plot_boxplot(eda_customers.data, outlier_feats, n_cols=3 ,  figsize = (20,  2))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:08.999566Z",
     "start_time": "2020-03-10T14:51:08.989567Z"
    }
   },
   "outputs": [],
   "source": [
    "# eda_customers.clean_outlier(outlier_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:09.015566Z",
     "start_time": "2020-03-10T14:51:09.003566Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_a = eda_customers.data[outlier_feats].copy()\n",
    "# h.plot_boxplot_comparison(df_b, df_a, outlier_feats, figsize= (12,  36), hspace=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step  8:  Impute missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:09.046566Z",
     "start_time": "2020-03-10T14:51:09.018566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the droped  features into a file.\n",
    "feats_dropped = eda_azdias.feat_info[ eda_azdias.feat_info.is_drop == 1].index\n",
    "\n",
    "# for c in feats_todrop:\n",
    "#     if c in eda_azdias.data.columns:\n",
    "#         eda_azdias.data.drop(columns = c, inplace = True)     \n",
    "        \n",
    "#     if c in eda_customers.data.columns:\n",
    "#         eda_customers.data.drop(columns = c, inplace = True)             \n",
    "    \n",
    "pd.Series(feats_dropped).sort_values().to_csv('feats_dropped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:09.061566Z",
     "start_time": "2020-03-10T14:51:09.051567Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_feats = eda_azdias.feat_info.loc[(eda_azdias.feat_info.type == 'numeric') & (eda_azdias.feat_info.is_drop == 0)].index\n",
    "numeric_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:09.077565Z",
     "start_time": "2020-03-10T14:51:09.065570Z"
    }
   },
   "outputs": [],
   "source": [
    "# eda_azdias.data[eda_azdias.feat_info.drop(numeric_feats).index].shape\n",
    "eda_azdias.data.columns.drop(numeric_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:09.249567Z",
     "start_time": "2020-03-10T14:51:09.083569Z"
    }
   },
   "outputs": [],
   "source": [
    "impMedian = Imputer(strategy='median')\n",
    "impFreq = Imputer(strategy='most_frequent')\n",
    "\n",
    "# eda_azdias.data_imputed = pd.DataFrame(imputer.fit_transform(eda_azdias.data))\n",
    "# eda_customers.data_imputed = pd.DataFrame(imputer.fit_transform(eda_customers.data))\n",
    "# other_feats = eda_azdias.data.columns.drop(numeric_feats)\n",
    "# numeric_imputed = pd.DataFrame(impMedian.fit_transform(eda_azdias.data[numeric_feats]), columns = numeric_feats)\n",
    "# other_imputed = pd.DataFrame(impFreq.fit_transform(eda_azdias.data[other_feats]), columns =other_feats )\n",
    "# eda_azdias.data_imputed =  pd.concat([other_imputed, numeric_imputed], axis=0)\n",
    "# eda_azdias.data_imputed\n",
    "\n",
    "eda_azdias.data_imputed = pd.DataFrame(impFreq.fit_transform(eda_azdias.data),  columns=eda_azdias.data.columns)\n",
    "eda_customers.data_imputed = pd.DataFrame(impFreq.fit_transform(eda_customers.data),  columns=eda_customers.data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step  9:   Feature  Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:09.345565Z",
     "start_time": "2020-03-10T14:51:09.252567Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_azdias.data_scaled = pd.DataFrame(StandardScaler().fit_transform(eda_azdias.data_imputed) , \n",
    "                                         columns=eda_azdias.data.columns)\n",
    "eda_customers.data_scaled = pd.DataFrame(StandardScaler().fit_transform(eda_customers.data_imputed) , \n",
    "                                         columns=eda_customers.data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:10.945566Z",
     "start_time": "2020-03-10T14:51:09.350568Z"
    }
   },
   "outputs": [],
   "source": [
    "h.do_pca(eda_azdias, 200)\n",
    "\n",
    "print(f'total explained_variance:  {eda_azdias.pca.explained_variance_ratio_.sum()}')\n",
    "# print('explained_variance_ratio: ', pca.explained_variance_ratio_)\n",
    "# print('explained_variance: ', pca.explained_variance_)\n",
    "print('n_components: ', eda_azdias.pca.n_components_)\n",
    "\n",
    "h.scree_plot(eda_azdias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:12.180565Z",
     "start_time": "2020-03-10T14:51:10.948570Z"
    }
   },
   "outputs": [],
   "source": [
    "h.do_pca(eda_customers, 200)\n",
    "\n",
    "print(f'total explained_variance:  {eda_customers.pca.explained_variance_ratio_.sum()}')\n",
    "# print('explained_variance_ratio: ', pca.explained_variance_ratio_)\n",
    "# print('explained_variance: ', pca.explained_variance_)\n",
    "print('n_components: ', eda_customers.pca.n_components_)\n",
    "\n",
    "h.scree_plot(eda_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with KMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:12.702566Z",
     "start_time": "2020-03-10T14:51:12.184566Z"
    }
   },
   "outputs": [],
   "source": [
    "h.do_pca(eda_azdias, 200)\n",
    "h.do_pca(eda_customers, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:20.660565Z",
     "start_time": "2020-03-10T14:51:12.706567Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "centers = list(range(1,21))\n",
    "\n",
    "for center in centers:\n",
    "    _, score = h.get_kmeans_score(eda_customers.X_pca, center)\n",
    "    scores.append(score)\n",
    "    \n",
    "plt.plot(centers, scores, linestyle='--', marker='o', color='b')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('SSE vs. K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-29T12:44:57.675678Z",
     "start_time": "2020-02-29T12:33:07.193Z"
    }
   },
   "source": [
    "####  Clustering Comparison  Azdias vs Customers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:26.414567Z",
     "start_time": "2020-03-10T14:51:20.663565Z"
    }
   },
   "outputs": [],
   "source": [
    "model_c, score = h.get_kmeans_score(eda_customers.X_pca, 15)\n",
    "print(score)\n",
    "model_a, score = h.get_kmeans_score(eda_azdias.X_pca, 15)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:26.890567Z",
     "start_time": "2020-03-10T14:51:26.419566Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_c = model_c.predict(eda_customers.X_pca)\n",
    "preds_a = model_a.predict(eda_azdias.X_pca)\n",
    "\n",
    "counts_c, counts_a = h.plot_cluster_comparison(preds_c, preds_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:26.906569Z",
     "start_time": "2020-03-10T14:51:26.893567Z"
    }
   },
   "outputs": [],
   "source": [
    "comp_diff_s = (counts_c.percent - counts_a.percent).sort_values(ascending=False)\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'cluster': comp_diff_s.index,\n",
    "        'diff_pct': comp_diff_s.values\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T14:51:26.922568Z",
     "start_time": "2020-03-10T14:51:26.910570Z"
    }
   },
   "outputs": [],
   "source": [
    "h.list_component(eda_customers,  6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:08:10.515956Z",
     "start_time": "2020-03-10T15:08:10.393958Z"
    }
   },
   "outputs": [],
   "source": [
    "# mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')\n",
    "mailout_train = pd.read_pickle ('..//data//mailout_train.p')    \n",
    "mailout_train.shape\n",
    "\n",
    "# read in feature info file\n",
    "feat_info = pd.read_csv('./feats_info.csv', sep=';', names=['feat', 'type', 'unknow'])\n",
    "feat_info.set_index('feat', inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Preparing and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:08:10.578958Z",
     "start_time": "2020-03-10T15:08:10.552958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set contains only 1.24% customers with positive response\n"
     ]
    }
   ],
   "source": [
    "positive_cnts = mailout_train[mailout_train['RESPONSE'] == 1].shape[0]\n",
    "total_cnts = mailout_train.shape[0]\n",
    " \n",
    "print(f'The train set contains only {positive_cnts / total_cnts *100 :1.2f}% customers with positive response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:08:10.911958Z",
     "start_time": "2020-03-10T15:08:10.580959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([113.,   0.,   0.,   0.,   0.,  16., 229.,   2.,   0.,   0.,   0.,\n",
       "          0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "          3.]),\n",
       " array([0.        , 0.0293837 , 0.05876739, 0.08815109, 0.11753478,\n",
       "        0.14691848, 0.17630218, 0.20568587, 0.23506957, 0.26445327,\n",
       "        0.29383696, 0.32322066, 0.35260435, 0.38198805, 0.41137175,\n",
       "        0.44075544, 0.47013914, 0.49952283, 0.52890653, 0.55829023,\n",
       "        0.58767392, 0.61705762, 0.64644131, 0.67582501, 0.70520871,\n",
       "        0.7345924 , 0.7639761 , 0.7933598 , 0.82274349, 0.85212719,\n",
       "        0.88151088, 0.91089458, 0.94027828, 0.96966197, 0.99904567]),\n",
       " <a list of 34 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract RESPONSE column\n",
    "response = mailout_train['RESPONSE']\n",
    "\n",
    "# drop RESPONSE column\n",
    "mailout_train.drop(labels=['RESPONSE'], axis=1, inplace=True)\n",
    "\n",
    "# find features to drop because of many missing values\n",
    "missing_per_column = mailout_train.isnull().mean()\n",
    "\n",
    "plt.hist(missing_per_column, bins=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:08:19.463956Z",
     "start_time": "2020-03-10T15:08:10.913958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Delete undefined, multiple missing values and duplicate features ...\n",
      "Before cleaning, Number of columns is 366 in mailout_train \n",
      "After cleaning, Number of columns is 300 in mailout_train \n",
      "Step 2: Convert missing and unknow values ...\n",
      "Number of missing values in mailout_train:\n",
      "Before converstion is 1955629\n",
      "Ater converstion IS 2342602\n",
      "Increase in missing values: 19.79 % \n",
      "Step 3: Delete the rows with more NaN values ...\n",
      "Before cleaning, Number of rows is 300 in mailout_train \n",
      "After cleaning, Number of columns is 300 in mailout_train \n",
      "  8292 lines deleted!\n",
      "Step 4: Re-encoding features...\n",
      "   Re-encoding: OST_WEST_KZ ...\n",
      "   Re-encoding: CAMEO_DEUG_2015 ...\n",
      "   Re-encoding: CAMEO_INTL_2015 ...\n",
      "Step 5: Split mixed features ...\n",
      "   Spliting: CAMEO_INTL_2015 ...\n",
      "   Spliting: LP_LEBENSPHASE_GROB ...\n",
      "   Spliting: PRAEGENDE_JUGENDJAHRE ...\n",
      "   Spliting: EINGEFUEGT_AM ...\n",
      "Step 6: Handling outliers ...\n",
      "Cleaning outliers for AGER_TYP  ...\n",
      "Cleaning outliers for ALTERSKATEGORIE_GROB  ...\n",
      "Cleaning outliers for ALTER_HH  ...\n",
      "Cleaning outliers for ANREDE_KZ  ...\n",
      "Cleaning outliers for ANZ_HAUSHALTE_AKTIV  ...\n",
      "Cleaning outliers for ANZ_HH_TITEL  ...\n",
      "Cleaning outliers for ANZ_KINDER  ...\n",
      "Cleaning outliers for ANZ_PERSONEN  ...\n",
      "Cleaning outliers for ANZ_TITEL  ...\n",
      "Cleaning outliers for ARBEIT  ...\n",
      "Cleaning outliers for BALLRAUM  ...\n",
      "Cleaning outliers for CAMEO_DEUG_2015  ...\n",
      "Cleaning outliers for CJT_GESAMTTYP  ...\n",
      "Cleaning outliers for D19_BUCH_CD  ...\n",
      "Cleaning outliers for D19_GESAMT_ANZ_12  ...\n",
      "Cleaning outliers for D19_GESAMT_ANZ_24  ...\n",
      "Cleaning outliers for D19_GESAMT_DATUM  ...\n",
      "Cleaning outliers for D19_GESAMT_OFFLINE_DATUM  ...\n",
      "Cleaning outliers for D19_GESAMT_ONLINE_DATUM  ...\n",
      "Cleaning outliers for D19_KONSUMTYP  ...\n",
      "Cleaning outliers for D19_SONSTIGE  ...\n",
      "Cleaning outliers for D19_SOZIALES  ...\n",
      "Cleaning outliers for D19_VERSAND_ANZ_24  ...\n",
      "Cleaning outliers for D19_VERSAND_DATUM  ...\n",
      "Cleaning outliers for D19_VERSAND_OFFLINE_DATUM  ...\n",
      "Cleaning outliers for D19_VERSAND_ONLINE_DATUM  ...\n",
      "Cleaning outliers for D19_VOLLSORTIMENT  ...\n",
      "Cleaning outliers for DSL_FLAG  ...\n",
      "Cleaning outliers for EINGEZOGENAM_HH_JAHR  ...\n",
      "Cleaning outliers for EWDICHTE  ...\n",
      "Cleaning outliers for FINANZTYP  ...\n",
      "Cleaning outliers for FINANZ_ANLEGER  ...\n",
      "Cleaning outliers for FINANZ_HAUSBAUER  ...\n",
      "Cleaning outliers for FINANZ_MINIMALIST  ...\n",
      "Cleaning outliers for FINANZ_SPARER  ...\n",
      "Cleaning outliers for FINANZ_UNAUFFAELLIGER  ...\n",
      "Cleaning outliers for FINANZ_VORSORGER  ...\n",
      "Cleaning outliers for GEBAEUDETYP  ...\n",
      "Cleaning outliers for GEBAEUDETYP_RASTER  ...\n",
      "Cleaning outliers for GEBURTSJAHR  ...\n",
      "Cleaning outliers for GFK_URLAUBERTYP  ...\n",
      "Cleaning outliers for GREEN_AVANTGARDE  ...\n",
      "Cleaning outliers for HEALTH_TYP  ...\n",
      "Cleaning outliers for HH_DELTA_FLAG  ...\n",
      "Cleaning outliers for HH_EINKOMMEN_SCORE  ...\n",
      "Cleaning outliers for INNENSTADT  ...\n",
      "Cleaning outliers for KBA05_ALTER1  ...\n",
      "Cleaning outliers for KBA05_ALTER2  ...\n",
      "Cleaning outliers for KBA05_ALTER3  ...\n",
      "Cleaning outliers for KBA05_ALTER4  ...\n",
      "Cleaning outliers for KBA05_ANHANG  ...\n",
      "Cleaning outliers for KBA05_ANTG1  ...\n",
      "Cleaning outliers for KBA05_ANTG2  ...\n",
      "Cleaning outliers for KBA05_ANTG3  ...\n",
      "Cleaning outliers for KBA05_ANTG4  ...\n",
      "Cleaning outliers for KBA05_AUTOQUOT  ...\n",
      "Cleaning outliers for KBA05_BAUMAX  ...\n",
      "Cleaning outliers for KBA05_CCM1  ...\n",
      "Cleaning outliers for KBA05_CCM2  ...\n",
      "Cleaning outliers for KBA05_CCM3  ...\n",
      "Cleaning outliers for KBA05_CCM4  ...\n",
      "Cleaning outliers for KBA05_DIESEL  ...\n",
      "Cleaning outliers for KBA05_FRAU  ...\n",
      "Cleaning outliers for KBA05_GBZ  ...\n",
      "Cleaning outliers for KBA05_HERST1  ...\n",
      "Cleaning outliers for KBA05_HERST2  ...\n",
      "Cleaning outliers for KBA05_HERST3  ...\n",
      "Cleaning outliers for KBA05_HERST4  ...\n",
      "Cleaning outliers for KBA05_HERST5  ...\n",
      "Cleaning outliers for KBA05_HERSTTEMP  ...\n",
      "Cleaning outliers for KBA05_KRSAQUOT  ...\n",
      "Cleaning outliers for KBA05_KRSHERST1  ...\n",
      "Cleaning outliers for KBA05_KRSHERST2  ...\n",
      "Cleaning outliers for KBA05_KRSHERST3  ...\n",
      "Cleaning outliers for KBA05_KRSKLEIN  ...\n",
      "Cleaning outliers for KBA05_KRSOBER  ...\n",
      "Cleaning outliers for KBA05_KRSVAN  ...\n",
      "Cleaning outliers for KBA05_KRSZUL  ...\n",
      "Cleaning outliers for KBA05_KW1  ...\n",
      "Cleaning outliers for KBA05_KW2  ...\n",
      "Cleaning outliers for KBA05_KW3  ...\n",
      "Cleaning outliers for KBA05_MAXAH  ...\n",
      "Cleaning outliers for KBA05_MAXBJ  ...\n",
      "Cleaning outliers for KBA05_MAXHERST  ...\n",
      "Cleaning outliers for KBA05_MAXSEG  ...\n",
      "Cleaning outliers for KBA05_MAXVORB  ...\n",
      "Cleaning outliers for KBA05_MOD1  ...\n",
      "Cleaning outliers for KBA05_MOD2  ...\n",
      "Cleaning outliers for KBA05_MOD3  ...\n",
      "Cleaning outliers for KBA05_MOD4  ...\n",
      "Cleaning outliers for KBA05_MOD8  ...\n",
      "Cleaning outliers for KBA05_MODTEMP  ...\n",
      "Cleaning outliers for KBA05_MOTOR  ...\n",
      "Cleaning outliers for KBA05_MOTRAD  ...\n",
      "Cleaning outliers for KBA05_SEG1  ...\n",
      "Cleaning outliers for KBA05_SEG10  ...\n",
      "Cleaning outliers for KBA05_SEG2  ...\n",
      "Cleaning outliers for KBA05_SEG3  ...\n",
      "Cleaning outliers for KBA05_SEG4  ...\n",
      "Cleaning outliers for KBA05_SEG5  ...\n",
      "Cleaning outliers for KBA05_SEG6  ...\n",
      "Cleaning outliers for KBA05_SEG7  ...\n",
      "Cleaning outliers for KBA05_SEG8  ...\n",
      "Cleaning outliers for KBA05_SEG9  ...\n",
      "Cleaning outliers for KBA05_VORB0  ...\n",
      "Cleaning outliers for KBA05_VORB1  ...\n",
      "Cleaning outliers for KBA05_VORB2  ...\n",
      "Cleaning outliers for KBA05_ZUL1  ...\n",
      "Cleaning outliers for KBA05_ZUL2  ...\n",
      "Cleaning outliers for KBA05_ZUL3  ...\n",
      "Cleaning outliers for KBA05_ZUL4  ...\n",
      "Cleaning outliers for KBA13_ALTERHALTER_30  ...\n",
      "Cleaning outliers for KBA13_ALTERHALTER_45  ...\n",
      "Cleaning outliers for KBA13_ALTERHALTER_60  ...\n",
      "Cleaning outliers for KBA13_ALTERHALTER_61  ...\n",
      "Cleaning outliers for KBA13_ANTG1  ...\n",
      "Cleaning outliers for KBA13_ANTG2  ...\n",
      "Cleaning outliers for KBA13_ANTG3  ...\n",
      "Cleaning outliers for KBA13_ANTG4  ...\n",
      "Cleaning outliers for KBA13_ANZAHL_PKW  ...\n",
      "Cleaning outliers for KBA13_AUDI  ...\n",
      "Cleaning outliers for KBA13_AUTOQUOTE  ...\n",
      "Cleaning outliers for KBA13_BAUMAX  ...\n",
      "Cleaning outliers for KBA13_BJ_1999  ...\n",
      "Cleaning outliers for KBA13_BJ_2000  ...\n",
      "Cleaning outliers for KBA13_BJ_2004  ...\n",
      "Cleaning outliers for KBA13_BJ_2006  ...\n",
      "Cleaning outliers for KBA13_BJ_2008  ...\n",
      "Cleaning outliers for KBA13_BJ_2009  ...\n",
      "Cleaning outliers for KBA13_BMW  ...\n",
      "Cleaning outliers for KBA13_CCM_0_1400  ...\n",
      "Cleaning outliers for KBA13_CCM_1000  ...\n",
      "Cleaning outliers for KBA13_CCM_1200  ...\n",
      "Cleaning outliers for KBA13_CCM_1400  ...\n",
      "Cleaning outliers for KBA13_CCM_1401_2500  ...\n",
      "Cleaning outliers for KBA13_CCM_1500  ...\n",
      "Cleaning outliers for KBA13_CCM_1600  ...\n",
      "Cleaning outliers for KBA13_CCM_1800  ...\n",
      "Cleaning outliers for KBA13_CCM_2000  ...\n",
      "Cleaning outliers for KBA13_CCM_2500  ...\n",
      "Cleaning outliers for KBA13_CCM_2501  ...\n",
      "Cleaning outliers for KBA13_CCM_3000  ...\n",
      "Cleaning outliers for KBA13_CCM_3001  ...\n",
      "Cleaning outliers for KBA13_FAB_ASIEN  ...\n",
      "Cleaning outliers for KBA13_FAB_SONSTIGE  ...\n",
      "Cleaning outliers for KBA13_FIAT  ...\n",
      "Cleaning outliers for KBA13_FORD  ...\n",
      "Cleaning outliers for KBA13_GBZ  ...\n",
      "Cleaning outliers for KBA13_HALTER_20  ...\n",
      "Cleaning outliers for KBA13_HALTER_25  ...\n",
      "Cleaning outliers for KBA13_HALTER_30  ...\n",
      "Cleaning outliers for KBA13_HALTER_35  ...\n",
      "Cleaning outliers for KBA13_HALTER_40  ...\n",
      "Cleaning outliers for KBA13_HALTER_45  ...\n",
      "Cleaning outliers for KBA13_HALTER_50  ...\n",
      "Cleaning outliers for KBA13_HALTER_55  ...\n",
      "Cleaning outliers for KBA13_HALTER_60  ...\n",
      "Cleaning outliers for KBA13_HALTER_65  ...\n",
      "Cleaning outliers for KBA13_HALTER_66  ...\n",
      "Cleaning outliers for KBA13_HERST_ASIEN  ...\n",
      "Cleaning outliers for KBA13_HERST_AUDI_VW  ...\n",
      "Cleaning outliers for KBA13_HERST_BMW_BENZ  ...\n",
      "Cleaning outliers for KBA13_HERST_EUROPA  ...\n",
      "Cleaning outliers for KBA13_HERST_FORD_OPEL  ...\n",
      "Cleaning outliers for KBA13_HERST_SONST  ...\n",
      "Cleaning outliers for KBA13_HHZ  ...\n",
      "Cleaning outliers for KBA13_KMH_0_140  ...\n",
      "Cleaning outliers for KBA13_KMH_110  ...\n",
      "Cleaning outliers for KBA13_KMH_140  ...\n",
      "Cleaning outliers for KBA13_KMH_140_210  ...\n",
      "Cleaning outliers for KBA13_KMH_180  ...\n",
      "Cleaning outliers for KBA13_KMH_210  ...\n",
      "Cleaning outliers for KBA13_KMH_211  ...\n",
      "Cleaning outliers for KBA13_KMH_250  ...\n",
      "Cleaning outliers for KBA13_KMH_251  ...\n",
      "Cleaning outliers for KBA13_KRSAQUOT  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning outliers for KBA13_KRSHERST_AUDI_VW  ...\n",
      "Cleaning outliers for KBA13_KRSHERST_BMW_BENZ  ...\n",
      "Cleaning outliers for KBA13_KRSHERST_FORD_OPEL  ...\n",
      "Cleaning outliers for KBA13_KRSSEG_KLEIN  ...\n",
      "Cleaning outliers for KBA13_KRSSEG_OBER  ...\n",
      "Cleaning outliers for KBA13_KRSSEG_VAN  ...\n",
      "Cleaning outliers for KBA13_KRSZUL_NEU  ...\n",
      "Cleaning outliers for KBA13_KW_0_60  ...\n",
      "Cleaning outliers for KBA13_KW_110  ...\n",
      "Cleaning outliers for KBA13_KW_120  ...\n",
      "Cleaning outliers for KBA13_KW_121  ...\n",
      "Cleaning outliers for KBA13_KW_30  ...\n",
      "Cleaning outliers for KBA13_KW_40  ...\n",
      "Cleaning outliers for KBA13_KW_50  ...\n",
      "Cleaning outliers for KBA13_KW_60  ...\n",
      "Cleaning outliers for KBA13_KW_61_120  ...\n",
      "Cleaning outliers for KBA13_KW_70  ...\n",
      "Cleaning outliers for KBA13_KW_80  ...\n",
      "Cleaning outliers for KBA13_KW_90  ...\n",
      "Cleaning outliers for KBA13_MAZDA  ...\n",
      "Cleaning outliers for KBA13_MERCEDES  ...\n",
      "Cleaning outliers for KBA13_MOTOR  ...\n",
      "Cleaning outliers for KBA13_NISSAN  ...\n",
      "Cleaning outliers for KBA13_OPEL  ...\n",
      "Cleaning outliers for KBA13_PEUGEOT  ...\n",
      "Cleaning outliers for KBA13_RENAULT  ...\n",
      "Cleaning outliers for KBA13_SEG_GELAENDEWAGEN  ...\n",
      "Cleaning outliers for KBA13_SEG_GROSSRAUMVANS  ...\n",
      "Cleaning outliers for KBA13_SEG_KLEINST  ...\n",
      "Cleaning outliers for KBA13_SEG_KLEINWAGEN  ...\n",
      "Cleaning outliers for KBA13_SEG_KOMPAKTKLASSE  ...\n",
      "Cleaning outliers for KBA13_SEG_MINIVANS  ...\n",
      "Cleaning outliers for KBA13_SEG_MINIWAGEN  ...\n",
      "Cleaning outliers for KBA13_SEG_MITTELKLASSE  ...\n",
      "Cleaning outliers for KBA13_SEG_OBEREMITTELKLASSE  ...\n",
      "Cleaning outliers for KBA13_SEG_OBERKLASSE  ...\n",
      "Cleaning outliers for KBA13_SEG_SONSTIGE  ...\n",
      "Cleaning outliers for KBA13_SEG_SPORTWAGEN  ...\n",
      "Cleaning outliers for KBA13_SEG_UTILITIES  ...\n",
      "Cleaning outliers for KBA13_SEG_VAN  ...\n",
      "Cleaning outliers for KBA13_SEG_WOHNMOBILE  ...\n",
      "Cleaning outliers for KBA13_SITZE_4  ...\n",
      "Cleaning outliers for KBA13_SITZE_5  ...\n",
      "Cleaning outliers for KBA13_SITZE_6  ...\n",
      "Cleaning outliers for KBA13_TOYOTA  ...\n",
      "Cleaning outliers for KBA13_VORB_0  ...\n",
      "Cleaning outliers for KBA13_VORB_1  ...\n",
      "Cleaning outliers for KBA13_VORB_1_2  ...\n",
      "Cleaning outliers for KBA13_VORB_2  ...\n",
      "Cleaning outliers for KBA13_VORB_3  ...\n",
      "Cleaning outliers for KBA13_VW  ...\n",
      "Cleaning outliers for KKK  ...\n",
      "Cleaning outliers for KK_KUNDENTYP  ...\n",
      "Cleaning outliers for KONSUMNAEHE  ...\n",
      "Cleaning outliers for KONSUMZELLE  ...\n",
      "Cleaning outliers for LP_FAMILIE_GROB  ...\n",
      "Cleaning outliers for LP_STATUS_FEIN  ...\n",
      "Cleaning outliers for MIN_GEBAEUDEJAHR  ...\n",
      "Cleaning outliers for MOBI_RASTER  ...\n",
      "Cleaning outliers for MOBI_REGIO  ...\n",
      "Cleaning outliers for NATIONALITAET_KZ  ...\n",
      "Cleaning outliers for ONLINE_AFFINITAET  ...\n",
      "Cleaning outliers for ORTSGR_KLS9  ...\n",
      "Cleaning outliers for OST_WEST_KZ  ...\n",
      "Cleaning outliers for PLZ8_ANTG1  ...\n",
      "Cleaning outliers for PLZ8_ANTG2  ...\n",
      "Cleaning outliers for PLZ8_ANTG3  ...\n",
      "Cleaning outliers for PLZ8_ANTG4  ...\n",
      "Cleaning outliers for PLZ8_BAUMAX  ...\n",
      "Cleaning outliers for PLZ8_GBZ  ...\n",
      "Cleaning outliers for PLZ8_HHZ  ...\n",
      "Cleaning outliers for REGIOTYP  ...\n",
      "Cleaning outliers for RELAT_AB  ...\n",
      "Cleaning outliers for RETOURTYP_BK_S  ...\n",
      "Cleaning outliers for SEMIO_DOM  ...\n",
      "Cleaning outliers for SEMIO_ERL  ...\n",
      "Cleaning outliers for SEMIO_FAM  ...\n",
      "Cleaning outliers for SEMIO_KAEM  ...\n",
      "Cleaning outliers for SEMIO_KRIT  ...\n",
      "Cleaning outliers for SEMIO_KULT  ...\n",
      "Cleaning outliers for SEMIO_LUST  ...\n",
      "Cleaning outliers for SEMIO_MAT  ...\n",
      "Cleaning outliers for SEMIO_PFLICHT  ...\n",
      "Cleaning outliers for SEMIO_RAT  ...\n",
      "Cleaning outliers for SEMIO_REL  ...\n",
      "Cleaning outliers for SEMIO_SOZ  ...\n",
      "Cleaning outliers for SEMIO_TRADV  ...\n",
      "Cleaning outliers for SEMIO_VERT  ...\n",
      "Cleaning outliers for SHOPPER_TYP  ...\n",
      "Cleaning outliers for SOHO_KZ  ...\n",
      "Cleaning outliers for UNGLEICHENN_FLAG  ...\n",
      "Cleaning outliers for VERS_TYP  ...\n",
      "Cleaning outliers for WOHNDAUER_2008  ...\n",
      "Cleaning outliers for WOHNLAGE  ...\n",
      "Cleaning outliers for W_KEIT_KIND_HH  ...\n",
      "Cleaning outliers for ZABEOTYP  ...\n",
      "Cleaning outliers for D19_KONSUMTYP_MAX  ...\n",
      "Cleaning outliers for EXTSEL992  ...\n",
      "Cleaning outliers for VHN  ...\n",
      "Cleaning outliers for GEMEINDETYP  ...\n",
      "Cleaning outliers for VK_DHT4A  ...\n",
      "Cleaning outliers for VK_DISTANZ  ...\n",
      "Cleaning outliers for VK_ZG11  ...\n",
      "Cleaning outliers for CJT_KATALOGNUTZER  ...\n",
      "Cleaning outliers for CJT_TYP_1  ...\n",
      "Cleaning outliers for CJT_TYP_2  ...\n",
      "Cleaning outliers for CJT_TYP_3  ...\n",
      "Cleaning outliers for CJT_TYP_4  ...\n",
      "Cleaning outliers for CJT_TYP_5  ...\n",
      "Cleaning outliers for CJT_TYP_6  ...\n",
      "Cleaning outliers for AKT_DAT_KL  ...\n",
      "Cleaning outliers for FIRMENDICHTE  ...\n",
      "Cleaning outliers for KOMBIALTER  ...\n",
      "Cleaning outliers for RT_KEIN_ANREIZ  ...\n",
      "Cleaning outliers for RT_SCHNAEPPCHEN  ...\n",
      "Cleaning outliers for RT_UEBERGROESSE  ...\n",
      "Cleaning outliers for STRUKTURTYP  ...\n",
      "Cleaning outliers for UMFELD_ALT  ...\n",
      "Cleaning outliers for UMFELD_JUNG  ...\n",
      "Cleaning outliers for VERDICHTUNGSRAUM  ...\n",
      "Cleaning outliers for CAMEO_INTL_2015_SPLIT_WEALTH  ...\n",
      "Cleaning outliers for CAMEO_INTL_2015_SPLIT_LIFE_STAGE  ...\n",
      "Cleaning outliers for LP_LEBENSPHASE_GROB_SPLIT_FAMILY  ...\n",
      "Cleaning outliers for LP_LEBENSPHASE_GROB_SPLIT_AGE  ...\n",
      "Cleaning outliers for LP_LEBENSPHASE_GROB_SPLIT_INCOME  ...\n",
      "Cleaning outliers for PRAEGENDE_JUGENDJAHRE_SPLIT_DECADE  ...\n",
      "Cleaning outliers for PRAEGENDE_JUGENDJAHRE_SPLIT_MOVEMENT  ...\n",
      "Step 7: Estimating NaN values with median ...\n",
      "Step 8: Feature scaling ...\n",
      "Data Cleaning done !\n"
     ]
    }
   ],
   "source": [
    "# read in feature info file\n",
    "# feat_info = pd.read_csv('./feats_info.csv', sep=';', names=['feat', 'type', 'unknown'])\n",
    "# feat_info.set_index('feat', inplace =True)\n",
    "\n",
    "eda_mailout_train = eda.EDA(mailout_train, feat_info, label = 'mailout_train')\n",
    "\n",
    "#  Data Cleaning\n",
    "eda_mailout_train.data_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:08:19.479957Z",
     "start_time": "2020-03-10T15:08:19.466957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34670,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = response.loc[mailout_train.index]\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T08:55:35.197973Z",
     "start_time": "2020-03-01T08:55:35.182973Z"
    }
   },
   "source": [
    "### Preparing and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:08:19.605956Z",
     "start_time": "2020-03-10T15:08:19.481957Z"
    }
   },
   "outputs": [],
   "source": [
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(\n",
    "    eda_mailout_train.data_scaled, \n",
    "    response, \n",
    "    test_size=0.33, \n",
    "    shuffle=True,\n",
    "    random_state=h.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:11:08.728543Z",
     "start_time": "2020-03-10T15:08:19.606957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: logistic regression,  Best ROC AUC score:  0.717432629811176\n",
      "Model: bagging,  Best ROC AUC score:  0.558950952088307\n",
      "Model: lgbmclassifier,  Best ROC AUC score:  0.7399174034502856\n"
     ]
    }
   ],
   "source": [
    "lrm = LogisticRegression(random_state=h.RANDOM_STATE)\n",
    "bagm = BaggingClassifier()\n",
    "lgbm = lgb.LGBMClassifier(random_state=h.RANDOM_STATE,application='binary')\n",
    "\n",
    "model_dict = {\n",
    "    'logistic regression': lrm,    \n",
    "    'bagging': bagm,\n",
    "    'lgbmclassifier': lgbm,\n",
    "}\n",
    "\n",
    "h.build_roc_auc(model_dict, {},eda_mailout_train.data_scaled, response)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LGBM classifier got a slightly better score so I'll use it down below to train and tuning for the kaggle competition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. LGB Train and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:22:36.222597Z",
     "start_time": "2020-03-10T15:11:08.730540Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|                                                                                                          | 344/1000 [11:27<21:50,  2.00s/trial, best loss: -0.7813870186822359]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "KeyboardInterrupt                         Traceback (most recent call last)",
      "<ipython-input-9-ce7330c3fe70> in <module>\n     14 cv = 10\n     15 \n---> 16 best, trials, objective = t.search_hyperparameter(def_params, n_iter, cv ,train_data, train_targets)\n     17 \n     18 model = t.build_model(best, def_params)\n",
      "D:\\udacity\\dsnd\\p3\\udacity-dsnd-capstone-arvato\\ilikeds\\train_classifier.py in search_hyperparameter(def_params, n_iter, cv, train_data, train_targets)\n     66             max_evals=n_iter, # maximum number of iterations\n     67             trials=trials, # logging\n---> 68             rstate=np.random.RandomState(h.RANDOM_STATE), # fixing random state for the reproducibility\n     69             )\n     70 \n",
      "E:\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\n    480             catch_eval_exceptions=catch_eval_exceptions,\n    481             return_argmin=return_argmin,\n--> 482             show_progressbar=show_progressbar,\n    483         )\n    484 \n",
      "E:\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py in fmin(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\n    684             catch_eval_exceptions=catch_eval_exceptions,\n    685             return_argmin=return_argmin,\n--> 686             show_progressbar=show_progressbar,\n    687         )\n    688 \n",
      "E:\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\n    507 \n    508     # next line is where the fmin is actually executed\n--> 509     rval.exhaust()\n    510 \n    511     if return_argmin:\n",
      "E:\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py in exhaust(self)\n    328     def exhaust(self):\n    329         n_done = len(self.trials)\n--> 330         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n    331         self.trials.refresh()\n    332         return self\n",
      "E:\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py in run(self, N, block_until_done)\n    284                 else:\n    285                     # -- loop over trials and do the jobs directly\n--> 286                     self.serial_evaluate()\n    287 \n    288                 self.trials.refresh()\n",
      "E:\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py in serial_evaluate(self, N)\n    163                 ctrl = base.Ctrl(self.trials, current_trial=trial)\n    164                 try:\n--> 165                     result = self.domain.evaluate(spec, ctrl)\n    166                 except Exception as e:\n    167                     logger.error(\"job exception: %s\" % str(e))\n",
      "E:\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py in evaluate(self, config, ctrl, attach_attachments)\n    892                 print_node_on_error=self.rec_eval_print_node_on_error,\n    893             )\n--> 894             rval = self.fn(pyll_rval)\n    895 \n    896         if isinstance(rval, (float, int, np.number)):\n",
      "D:\\udacity\\dsnd\\p3\\udacity-dsnd-capstone-arvato\\ilikeds\\train_classifier.py in objective(params, def_params, X, y)\n     50 \n     51             # and then conduct the cross validation with the same folds as before\n---> 52             score =-cross_val_score(clf, X, y, scoring=\"roc_auc\", n_jobs=-1).mean()\n     53 \n     54             return score\n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\n    389                                 fit_params=fit_params,\n    390                                 pre_dispatch=pre_dispatch,\n--> 391                                 error_score=error_score)\n    392     return cv_results['test_score']\n    393 \n",
      "E:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\n    230             return_times=True, return_estimator=return_estimator,\n    231             error_score=error_score)\n--> 232         for train, test in cv.split(X, y, groups))\n    233 \n    234     zipped_scores = list(zip(*scores))\n",
      "E:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self, iterable)\n    932 \n    933             with self._backend.retrieval_context():\n--> 934                 self.retrieve()\n    935             # Make sure that we get a last message telling us we are done\n    936             elapsed_time = time.time() - self._start_time\n",
      "E:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py in retrieve(self)\n    831             try:\n    832                 if getattr(self._backend, 'supports_timeout', False):\n--> 833                     self._output.extend(job.get(timeout=self.timeout))\n    834                 else:\n    835                     self._output.extend(job.get())\n",
      "E:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py in wrap_future_result(future, timeout)\n    519         AsyncResults.get from multiprocessing.\"\"\"\n    520         try:\n--> 521             return future.result(timeout=timeout)\n    522         except LokyTimeoutError:\n    523             raise TimeoutError()\n",
      "E:\\Anaconda3\\lib\\concurrent\\futures\\_base.py in result(self, timeout)\n    428                 return self.__get_result()\n    429 \n--> 430             self._condition.wait(timeout)\n    431 \n    432             if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "E:\\Anaconda3\\lib\\threading.py in wait(self, timeout)\n    294         try:    # restore state no matter what (e.g., KeyboardInterrupt)\n    295             if timeout is None:\n--> 296                 waiter.acquire()\n    297                 gotit = True\n    298             else:\n",
      "KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "def_params={\n",
    "        'learning_rate':  {'hpf' :  hp.loguniform('learning_rate', np.log(0.00001), np.log(0.0075)),'dtype' : 'float'},           \n",
    "        'num_leaves' :    {'hpf' : hp.quniform('num_leaves', 3, 15, 1),'dtype' : 'int'},     \n",
    "        'min_data_in_leaf' : {'hpf' : hp.quniform('min_data_in_leaf', 1000, 1500, 50),'dtype' : 'int'},     \n",
    "        'min_sum_hessian_in_leaf':  {'hpf' : hp.uniform('min_sum_hessian_in_leaf', 0.0005, 0.002),'dtype' : 'float'},               \n",
    "        'colsample_bytree': {'hpf': hp.uniform('colsample_bytree', 0.5, 0.9),'dtype' : 'float'},        \n",
    "        'reg_alpha': {'hpf': hp.uniform('reg_alpha', 0.3, 1.0),'dtype' : 'float'}, \n",
    "        'reg_lambda': {'hpf': hp.uniform('reg_lambda', 0, 0.6),'dtype' : 'float'}, \n",
    "        'max_bin' :    {'hpf' : hp.quniform('max_bin', 10, 80, 1),'dtype' : 'int'},    \n",
    "        'feature_fraction': {'hpf': hp.uniform('feature_fraction', 0.3, 0.7),'dtype' : 'float'},    \n",
    "}\n",
    "\n",
    "n_iter = 1000\n",
    "cv = 10\n",
    "\n",
    "best, trials, objective = t.search_hyperparameter(def_params, n_iter, cv ,train_data, train_targets)\n",
    "\n",
    "model = t.build_model(best, def_params)\n",
    "\n",
    "model.fit(train_data,train_targets)\n",
    "\n",
    "t.evaluate_model(model, objective, best, test_data, test_targets)\n",
    "\n",
    "sa_results_df = t.plot_result(trials.trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T09:05:43.813546Z",
     "start_time": "2020-03-01T09:05:43.804547Z"
    }
   },
   "source": [
    "### Step 6. Top 15 most important features of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:22:36.254600Z",
     "start_time": "2020-03-10T15:08:11.356Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, max_num_features = 30, figsize=(10,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer  this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:22:36.256598Z",
     "start_time": "2020-03-10T15:08:11.507Z"
    }
   },
   "outputs": [],
   "source": [
    "# mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')\n",
    "mailout_test = pd.read_pickle ('..//data//mailout_test.p')    \n",
    "mailout_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:22:36.257598Z",
     "start_time": "2020-03-10T15:08:11.516Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_mailout_test = eda.EDA(mailout_test, feat_info, label = 'mailout_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:22:36.259599Z",
     "start_time": "2020-03-10T15:08:11.528Z"
    }
   },
   "outputs": [],
   "source": [
    "LNR = mailout_test.LNR.copy()\n",
    "LNR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:22:36.260597Z",
     "start_time": "2020-03-10T15:08:11.540Z"
    }
   },
   "outputs": [],
   "source": [
    "eda_mailout_test.data_pipeline(clean_rows = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:22:36.261599Z",
     "start_time": "2020-03-10T15:08:11.550Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit and predict\n",
    "preds_test = model.predict_proba(eda_mailout_test.data_scaled)[:,1]\n",
    "preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T15:22:36.262598Z",
     "start_time": "2020-03-10T15:08:11.561Z"
    }
   },
   "outputs": [],
   "source": [
    "# create submission file\n",
    "preds_test = pd.concat([LNR, pd.Series(preds_test)], axis = 1)\n",
    "preds_test.rename(columns={0:'RESPONSE'}, inplace= True)\n",
    "preds_test.to_csv('MAILOUT_TEST.csv') "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.347px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
